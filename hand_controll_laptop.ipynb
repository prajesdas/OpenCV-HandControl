{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db72bfb1-a6c7-4b73-aed8-e39d07ba84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the dimensions of the screen\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Load the hand cascade for detection\n",
    "hand_cascade = cv2.CascadeClassifier(r\"C:\\Users\\PRAJES DAS\\OneDrive\\Desktop\\4th Year Project\\human activity tracker\\haarcascade_hand.xml\")\n",
    "\n",
    "# Parameters for click, scroll, and mouse movement actions\n",
    "prev_x, prev_y = 0, 0\n",
    "scrolling = False\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect hands in the frame\n",
    "    hands = hand_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3, minSize=(50, 50))\n",
    "\n",
    "    if len(hands) > 0:\n",
    "        hx, hy, hw, hh = hands[0]  # Assuming one hand is detected\n",
    "        hand_roi = gray[hy:hy+hh, hx:hx+hw]\n",
    "\n",
    "        # Apply thresholding to isolate the hand\n",
    "        _, hand_thresh = cv2.threshold(hand_roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(hand_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours:\n",
    "            max_contour = max(contours, key=cv2.contourArea)\n",
    "            hull = cv2.convexHull(max_contour, returnPoints=False)\n",
    "            hull = np.sort(hull, axis=0)  # Fix convexity defect issue\n",
    "            \n",
    "            if len(hull) > 3:  # Convexity defects require at least 3 points\n",
    "                defects = cv2.convexityDefects(max_contour, hull)\n",
    "                finger_count = 0\n",
    "\n",
    "                if defects is not None:\n",
    "                    for i in range(defects.shape[0]):\n",
    "                        s, e, f, d = defects[i, 0]\n",
    "                        start = tuple(max_contour[s][0])\n",
    "                        end = tuple(max_contour[e][0])\n",
    "                        far = tuple(max_contour[f][0])\n",
    "\n",
    "                        a = np.linalg.norm(np.array(far) - np.array(start))\n",
    "                        b = np.linalg.norm(np.array(far) - np.array(end))\n",
    "                        c = np.linalg.norm(np.array(start) - np.array(end))\n",
    "                        angle = np.arccos((b**2 + c**2 - a**2) / (2 * b * c))\n",
    "\n",
    "                        if angle < np.pi / 2:\n",
    "                            finger_count += 1\n",
    "\n",
    "                # Perform actions based on finger count\n",
    "                if finger_count == 1:\n",
    "                    pyautogui.scroll(10)  # Scroll up\n",
    "                elif finger_count == 2:\n",
    "                    pyautogui.scroll(-10)  # Scroll down\n",
    "                elif finger_count == 3:\n",
    "                    # Move mouse based on hand movement\n",
    "                    center_x = hx + hw // 2\n",
    "                    center_y = hy + hh // 2\n",
    "                    if prev_x and prev_y:\n",
    "                        dx = center_x - prev_x\n",
    "                        dy = center_y - prev_y\n",
    "                        pyautogui.moveRel(dx, dy)\n",
    "                    prev_x, prev_y = center_x, center_y\n",
    "                elif finger_count == 0:\n",
    "                    pyautogui.click()  # Click when fist is detected\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Gesture Tracking', frame)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c2f39-f93b-4701-bea0-f6069f21faae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
